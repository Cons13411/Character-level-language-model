{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import io\n",
    "import torch\n",
    "import codecs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the corpora, and breaking the lines into train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/shekspear.txt\"\n",
    "sentences = []\n",
    "with io.open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().lower()\n",
    "        if line:\n",
    "            sentences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sentences = sentences[-1000:]\n",
    "train_sentences = sentences[:-1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below, gets a line and convert each character in the line to its Unicode intiger. \n",
    "EOS_int represent the end of sentences, and we refer to it as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line, EOS_int=2, BOS_int = 1):\n",
    "    \"\"\"Turns a line of text into a tensor\n",
    "\n",
    "    Args:\n",
    "        line (str): A single line of text.\n",
    "        EOS_int (int, optional): End-of-sentence integer. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of integers (unicode values) for the characters in the `line`.\n",
    "    \"\"\"\n",
    "    tensor = []\n",
    "    for char in line:\n",
    "        char_int = ord(char)\n",
    "        tensor.append(char_int)\n",
    "        \n",
    "    tensor.append(EOS_int)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor represntation of character for ALI is equal to: [97, 108, 105, 2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor represntation of character for ALI is equal to: {line_to_tensor('ali')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset class to generate batches of sentences with maximum length of max_length, padding and a masked tensor to identify which cell represent a character and which is a padding cell. \n",
    "EOS = 2\n",
    "BOS = 1 # added in getitem function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textBatch(Dataset):\n",
    "    \n",
    "        def __init__(self, sentences, max_length):\n",
    "            self.line_tensor = []\n",
    "            for line in sentences:\n",
    "                tensor = self.line_to_tensor(line)\n",
    "                pad = [0] *(max_length-len(tensor))\n",
    "                paded_tensor = tensor + pad\n",
    "                mask = [1 if el>0 else 0 for el in paded_tensor]\n",
    "                self.line_tensor.append((paded_tensor,mask))\n",
    "            \n",
    "        def __len__(self):\n",
    "            #len(dataset)\n",
    "            return len(self.line_tensor)\n",
    "        \n",
    "        def __getitem__(self, index):\n",
    "            \n",
    "            paded_tensor, mask = self.line_tensor[index]\n",
    "            paded_tensor = torch.tensor(paded_tensor).view(1,-1)\n",
    "            input_sen = torch.zeros(paded_tensor.size()).view(1,-1)\n",
    "            input_sen[0,0] = 1\n",
    "            input_sen[0,1:] = paded_tensor[0,:-1]\n",
    "            return input_sen , paded_tensor , torch.tensor(mask)\n",
    "        \n",
    "        def line_to_tensor(self,line, EOS_int=2):\n",
    "            \"\"\"Turns a line of text into a tensor\n",
    "\n",
    "            Args:\n",
    "                line (str): A single line of text.\n",
    "                EOS_int (int, optional): End-of-sentence integer. Defaults to 1.\n",
    "\n",
    "            Returns:\n",
    "                list: a list of integers (unicode values) for the characters in the `line`.\n",
    "            \"\"\"\n",
    "            tensor = []\n",
    "            for char in line:\n",
    "                char_int = ord(char)\n",
    "                tensor.append(char_int)\n",
    "\n",
    "            tensor.append(EOS_int)\n",
    "            return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1., 104., 101., 108., 108., 111.,  32., 100., 101.,  97., 114.,\n",
      "            2.,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  1., 104., 111., 110., 101., 121.,   2.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.]]])\n",
      "tensor([[[104, 101, 108, 108, 111,  32, 100, 101,  97, 114,   2,   0,   0,   0,\n",
      "            0]],\n",
      "\n",
      "        [[104, 111, 110, 101, 121,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0]]])\n"
     ]
    }
   ],
   "source": [
    "data = textBatch(['hey man', 'hello dear', 'honey'], 15)\n",
    "train_loader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "for x,y,z in train_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the character level GRU lanuage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRULM(nn.Module):\n",
    "     def __init__(self, dim, n_layer,h_units, vocab_size, batch_size, gpu = 0, ):\n",
    "            super(GRULM, self).__init__()\n",
    "            self.dim = dim\n",
    "            self.num_layers = n_layer\n",
    "            self.vocab_size = vocab_size\n",
    "            self.hidden_units = h_units\n",
    "            self.batch_size = batch_size\n",
    "            self.embed = nn.Embedding(self.vocab_size,self.dim)\n",
    "            self.GRU = nn.GRU(self.dim,self.hidden_units,self.num_layers,batch_first=True)\n",
    "            self.lin= nn.Linear(self.hidden_units, self.vocab_size)\n",
    "    \n",
    "     def forward(self, x, hidden):\n",
    "            emb = self.embed(x)\n",
    "            output, hidden1 = self.GRU(emb.unsqueeze(1),hidden)\n",
    "            out1 = self.lin(output)\n",
    "\n",
    "            return out1, hidden1\n",
    "    \n",
    "     def init_hidden(self, batch_size):\n",
    "        \n",
    "         return  torch.zeros(self.num_layers, batch_size, self.hidden_units)\n",
    "     \n",
    "     def evaluate(self, dev_loader):\n",
    "        \n",
    "        self.train(mode=False)\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            total = 0\n",
    "            for data, target, masked in dev_loader:\n",
    "                \n",
    "                data = data.squeeze()\n",
    "                target = target.squeeze()\n",
    "                masked = masked.squeeze()\n",
    "                batch_loss = 0\n",
    "                \n",
    "                if len(data.size()) == 1:\n",
    "                    continue\n",
    "                    \n",
    "                hidden = self.init_hidden(data.size(0))\n",
    "                bs_total = 0\n",
    "                for charid  in range(data.size(1)) :\n",
    "                    output, hidden = model(data[:,charid].long(),hidden)\n",
    "                    target1 = target[:,charid].long()\n",
    "                    batch_loss += criterion(output.squeeze(), target1)\n",
    "                    bs_total += 1\n",
    "                    \n",
    "                avg_loss = batch_loss.item()/bs_total\n",
    "                losses.append(avg_loss)\n",
    "                total += 1\n",
    "        epoch_loss = sum(losses) / total\n",
    "        return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of batches and max length, and then computing the number of batches in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_lin_in_training(sentences, batch_size):\n",
    "    index = 0\n",
    "    for line in sentences:\n",
    "        if len(line) < max_length:\n",
    "            index +=1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used lines from the dataset: 31777\n",
      "Batch size (a power of 2): 32\n",
      "Number of steps to cover one epoch: 993\n"
     ]
    }
   ],
   "source": [
    "num_used_lines = num_lin_in_training(train_sentences, 32)\n",
    "print('Number of used lines from the dataset:', num_used_lines)\n",
    "print('Batch size (a power of 2):', int(batch_size))\n",
    "steps_per_epoch = int(num_used_lines/batch_size)\n",
    "print('Number of steps to cover one epoch:', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the train and eval loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = textBatch(train_sentences, max_length)\n",
    "train_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "eval_data  = textBatch(eval_sentences, max_length)\n",
    "eval_loader = DataLoader(eval_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru(model,trainloader, optim):\n",
    "    \n",
    "    losses = []\n",
    "    total = 0\n",
    "    \n",
    "    for data, target, masked in train_loader:\n",
    "        model.zero_grad()\n",
    "        model.train(mode=True)\n",
    "        \n",
    "        data = data.squeeze()\n",
    "        target = target.squeeze()\n",
    "        masked = masked.squeeze()\n",
    "\n",
    "\n",
    "        batch_loss = 0\n",
    "        if len(data.size()) == 1:\n",
    "            continue\n",
    "                \n",
    "        batch_size = data.size(0)\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for charid  in range(data.size(1)) :\n",
    "            output, hidden = model(data[:,charid].long(),hidden)\n",
    "            target1 = target[:,charid].long()\n",
    "            batch_loss += criterion(output.squeeze(), target1)\n",
    "        \n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "        avg_loss = batch_loss.item()/data.size(1)\n",
    "        losses.append(avg_loss)\n",
    "        total += 1\n",
    "    \n",
    "    return losses, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training procedure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep    0 |Train loss 1.376997 |Train PPL 3.962983 |Evaluation loss 0.999870 |Evaluation PPL 2.717927|Saved\n",
      "\n",
      "Ep    1 |Train loss 1.067120 |Train PPL 2.906995 |Evaluation loss 0.945112 |Evaluation PPL 2.573101|Saved\n",
      "\n",
      "Ep    2 |Train loss 1.012444 |Train PPL 2.752318 |Evaluation loss 0.923221 |Evaluation PPL 2.517385|Saved\n",
      "\n",
      "Ep    3 |Train loss 0.977649 |Train PPL 2.658200 |Evaluation loss 0.902607 |Evaluation PPL 2.466025|Saved\n",
      "\n",
      "Ep    4 |Train loss 0.951713 |Train PPL 2.590142 |Evaluation loss 0.890607 |Evaluation PPL 2.436608|Saved\n",
      "\n",
      "Ep    5 |Train loss 0.935696 |Train PPL 2.548986 |Evaluation loss 0.886302 |Evaluation PPL 2.426140|Saved\n",
      "\n",
      "Ep    6 |Train loss 0.924607 |Train PPL 2.520877 |Evaluation loss 0.882478 |Evaluation PPL 2.416881|Saved\n",
      "\n",
      "Ep    7 |Train loss 0.915676 |Train PPL 2.498465 |Evaluation loss 0.880973 |Evaluation PPL 2.413248|Saved\n",
      "\n",
      "Ep    8 |Train loss 0.908777 |Train PPL 2.481285 |Evaluation loss 0.876345 |Evaluation PPL 2.402104|Saved\n",
      "\n",
      "Ep    9 |Train loss 0.902846 |Train PPL 2.466612 |Evaluation loss 0.875174 |Evaluation PPL 2.399292|Saved\n",
      "\n",
      "Ep   10 |Train loss 0.897884 |Train PPL 2.454405 |Evaluation loss 0.871508 |Evaluation PPL 2.390514|Saved\n",
      "\n",
      "Ep   11 |Train loss 0.893664 |Train PPL 2.444069 |Evaluation loss 0.868401 |Evaluation PPL 2.383098|Saved\n",
      "\n",
      "Ep   12 |Train loss 0.889939 |Train PPL 2.434981 |Evaluation loss 0.866652 |Evaluation PPL 2.378934|Saved\n",
      "\n",
      "Ep   13 |Train loss 0.886878 |Train PPL 2.427539 |Evaluation loss 0.865972 |Evaluation PPL 2.377317|Saved\n",
      "\n",
      "Ep   14 |Train loss 0.883825 |Train PPL 2.420138 |Evaluation loss 0.867025 |Evaluation PPL 2.379820\n",
      "\n",
      "Ep   15 |Train loss 0.881153 |Train PPL 2.413681 |Evaluation loss 0.865691 |Evaluation PPL 2.376648|Saved\n",
      "\n",
      "Ep   16 |Train loss 0.878860 |Train PPL 2.408152 |Evaluation loss 0.863304 |Evaluation PPL 2.370981|Saved\n",
      "\n",
      "Ep   17 |Train loss 0.876728 |Train PPL 2.403023 |Evaluation loss 0.864001 |Evaluation PPL 2.372635\n",
      "\n",
      "Ep   18 |Train loss 0.874712 |Train PPL 2.398185 |Evaluation loss 0.864070 |Evaluation PPL 2.372798\n",
      "\n",
      "Ep   19 |Train loss 0.873157 |Train PPL 2.394459 |Evaluation loss 0.864262 |Evaluation PPL 2.373254\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-bf5f6fabf27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "model = GRULM(dim=100,n_layer=1,h_units=50, vocab_size=256, batch_size=batch_size, gpu = 0, )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                       weight_decay=0.0,\n",
    "                       betas=(0.9, 0.999),\n",
    "                       eps=1e-8,\n",
    "                       amsgrad=False)\n",
    "\n",
    "\n",
    "epoch = 20\n",
    "least_loss = 1000\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "for ep in range(epoch):\n",
    "    \n",
    "    print('Ep {:4d}'.format(ep), end='')\n",
    "\n",
    "    losses, total = train_gru(model, train_loader, optim)\n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_loss.append(epoch_loss)\n",
    "    \n",
    "    print(' |Train loss {:4f}'.format(epoch_loss), end='')\n",
    "    print(' |Train PPL {:4f}'.format(np.exp(epoch_loss)), end='')\n",
    "    \n",
    "    evaluate_loss = model.evaluate(eval_loader)\n",
    "    eval_loss.append(evaluate_loss)\n",
    "    \n",
    "    print(' |Evaluation loss {:4f}'.format(evaluate_loss), end='')\n",
    "    print(' |Evaluation PPL {:4f}'.format(np.exp(evaluate_loss)), end='')\n",
    "    \n",
    "    if least_loss > evaluate_loss:\n",
    "        least_loss = evaluate_loss\n",
    "        torch.save(model.state_dict(), './GRULM.pth')\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print('|Saved\\n')\n",
    "    else:\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep    0 |Train loss 1.394333 |Train PPL 4.032284 |Evaluation loss 0.978091 |Evaluation PPL 2.659373|Saved\n",
      "\n",
      "Ep    1 |Train loss 1.019600 |Train PPL 2.772086 |Evaluation loss 0.905296 |Evaluation PPL 2.472663|Saved\n",
      "\n",
      "Ep    2 |Train loss 0.947721 |Train PPL 2.579823 |Evaluation loss 0.883871 |Evaluation PPL 2.420251|Saved\n",
      "\n",
      "Ep    3 |Train loss 0.912410 |Train PPL 2.490317 |Evaluation loss 0.871749 |Evaluation PPL 2.391090|Saved\n",
      "\n",
      "Ep    4 |Train loss 0.890298 |Train PPL 2.435854 |Evaluation loss 0.862656 |Evaluation PPL 2.369446|Saved\n",
      "\n",
      "Ep    5 |Train loss 0.875049 |Train PPL 2.398994 |Evaluation loss 0.856866 |Evaluation PPL 2.355767|Saved\n",
      "\n",
      "Ep    6 |Train loss 0.863312 |Train PPL 2.371000 |Evaluation loss 0.847551 |Evaluation PPL 2.333924|Saved\n",
      "\n",
      "Ep    7 |Train loss 0.853533 |Train PPL 2.347928 |Evaluation loss 0.847126 |Evaluation PPL 2.332932|Saved\n",
      "\n",
      "Ep    8 |Train loss 0.845998 |Train PPL 2.330302 |Evaluation loss 0.842466 |Evaluation PPL 2.322087|Saved\n",
      "\n",
      "Ep    9 |Train loss 0.839131 |Train PPL 2.314355 |Evaluation loss 0.837197 |Evaluation PPL 2.309883|Saved\n",
      "\n",
      "Ep   10 |Train loss 0.833493 |Train PPL 2.301342 |Evaluation loss 0.832699 |Evaluation PPL 2.299516|Saved\n",
      "\n",
      "Ep   11 |Train loss 0.828429 |Train PPL 2.289720 |Evaluation loss 0.833304 |Evaluation PPL 2.300909\n",
      "\n",
      "Ep   12 |Train loss 0.823836 |Train PPL 2.279226 |Evaluation loss 0.831843 |Evaluation PPL 2.297549|Saved\n",
      "\n",
      "Ep   13 |Train loss 0.819972 |Train PPL 2.270437 |Evaluation loss 0.825755 |Evaluation PPL 2.283605|Saved\n",
      "\n",
      "Ep   14 |Train loss 0.816707 |Train PPL 2.263036 |Evaluation loss 0.828858 |Evaluation PPL 2.290701\n",
      "\n",
      "Ep   15 |Train loss 0.813350 |Train PPL 2.255450 |Evaluation loss 0.827287 |Evaluation PPL 2.287105\n",
      "\n",
      "Ep   16 |Train loss 0.810432 |Train PPL 2.248879 |Evaluation loss 0.822584 |Evaluation PPL 2.276374|Saved\n",
      "\n",
      "Ep   17 |Train loss 0.807704 |Train PPL 2.242752 |Evaluation loss 0.822476 |Evaluation PPL 2.276128|Saved\n",
      "\n",
      "Ep   18 |Train loss 0.805014 |Train PPL 2.236727 |Evaluation loss 0.821336 |Evaluation PPL 2.273535|Saved\n",
      "\n",
      "Ep   19 |Train loss 0.803194 |Train PPL 2.232661 |Evaluation loss 0.818145 |Evaluation PPL 2.266292|Saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "model = GRULM(dim=100,n_layer=2,h_units=50, vocab_size=256, batch_size=batch_size, gpu = 0, )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                       weight_decay=0.0,\n",
    "                       betas=(0.9, 0.999),\n",
    "                       eps=1e-8,\n",
    "                       amsgrad=False)\n",
    "\n",
    "writer = SummaryWriter(\"/Users/cons13411/PycharmProjects/deep N-Gram/\")\n",
    "\n",
    "\n",
    "epoch = 20\n",
    "least_loss = 1000\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "for ep in range(epoch):\n",
    "    print('Ep {:4d}'.format(ep), end='')\n",
    "    losses = []\n",
    "    total = 0\n",
    "    for data, target, masked in train_loader:\n",
    "        model.zero_grad()\n",
    "        model.train(mode=True)\n",
    "        data = data.squeeze()\n",
    "        target = target.squeeze()\n",
    "        masked = masked.squeeze()\n",
    "\n",
    "\n",
    "        batch_loss = 0\n",
    "        if len(data.size()) == 1:\n",
    "            continue\n",
    "                \n",
    "        batch_size = data.size(0)\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for charid  in range(data.size(1)) :\n",
    "            output, hidden = model(data[:,charid].long(),hidden)\n",
    "            target1 = target[:,charid].long()\n",
    "            batch_loss += criterion(output.squeeze(), target1)\n",
    "            \n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "        avg_loss = batch_loss.item()/data.size(1)\n",
    "        losses.append(avg_loss)\n",
    "        total += 1\n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_loss.append(epoch_loss)\n",
    "    print(' |Train loss {:4f}'.format(epoch_loss), end='')\n",
    "    print(' |Train PPL {:4f}'.format(np.exp(epoch_loss)), end='')\n",
    "    evaluate_loss = model.evaluate(eval_loader)\n",
    "    eval_loss.append(evaluate_loss)\n",
    "    print(' |Evaluation loss {:4f}'.format(evaluate_loss), end='')\n",
    "    print(' |Evaluation PPL {:4f}'.format(np.exp(evaluate_loss)), end='')\n",
    "    \n",
    "    if least_loss > evaluate_loss:\n",
    "        least_loss = evaluate_loss\n",
    "        torch.save(model.state_dict(), './GRULM.pth')\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print('|Saved\\n')\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall in my home immond stiel wiper,\u0002\n"
     ]
    }
   ],
   "source": [
    "seed  = 'shall i'\n",
    "txt = 'shall i'\n",
    "bt_size = 1\n",
    "temperature = 1\n",
    "hidden_state = best_model.init_hidden(bt_size)\n",
    "\n",
    "charids = []\n",
    "charids.append(1)\n",
    "for char in seed:\n",
    "    charids.append(ord(char))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for charid in charids:\n",
    "        charid = torch.tensor([charid])\n",
    "        output, hidden_state = best_model(charid, hidden_state)\n",
    "        \n",
    "        distribution = output.squeeze().div(temperature).exp()\n",
    "        guess = torch.multinomial(distribution, 1).item()\n",
    "        \n",
    "\n",
    "    txt += chr(guess)\n",
    "    while guess != 2:\n",
    "        charid = torch.tensor([guess])\n",
    "        output, hidden_state = best_model(charid, hidden_state)\n",
    "\n",
    "        probs = F.softmax(output, 2)\n",
    "        probs, picked_indexes = probs.topk(10)\n",
    "        picked_indexes = picked_indexes.numpy().squeeze()\n",
    "        probs = probs.numpy().flatten()\n",
    "        probs = probs / probs.sum()\n",
    "        guess = np.random.choice(picked_indexes, p=probs)\n",
    "        \n",
    "        txt += chr(guess)\n",
    "        \n",
    "#         if guess == 2:\n",
    "#             txt += '\\n'\n",
    "#             guess = np.random.randint(97, high=122)\n",
    "#             hidden_state = best_model.init_hidden(bt_size)\n",
    "        #print(guess)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of parameters in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "|   embed.weight   |   25600    |\n",
      "| GRU.weight_ih_l0 |   15000    |\n",
      "| GRU.weight_hh_l0 |    7500    |\n",
      "|  GRU.bias_ih_l0  |    150     |\n",
      "|  GRU.bias_hh_l0  |    150     |\n",
      "|    lin.weight    |   12800    |\n",
      "|     lin.bias     |    256     |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 61456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61456"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
